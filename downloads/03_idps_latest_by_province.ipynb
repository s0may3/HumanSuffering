{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# 03 â€” IDPs (latest snapshot by province)\n",
        "\n",
        "**Dataset (source file):** `raw_data/hdx_hapi_idps_afg.csv`  \n",
        "**Geo boundary used by the website:** `raw_data/geo/afghanistan_adm1.geojson`  \n",
        "**Website section:** `js/sections/idps.js`\n",
        "\n",
        "This notebook:\n",
        "1) reads raw IDPs data,\n",
        "2) filters to `admin_level=1` and a valid date + positive population,\n",
        "3) finds the latest snapshot date,\n",
        "4) aggregates by province,\n",
        "5) saves:\n",
        "   - cleaned snapshot rows to `dataset/cleaned/idps_admin1_latest_clean.csv`\n",
        "   - dropped rows to `dataset/cleaned/idps_dropped.csv`\n",
        "   - aggregates to `dataset/derived/idps_latest_by_province.csv` + `dataset/derived/idps_latest_total.json`\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "execution_count": null,
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "from pathlib import Path\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "RAW_DIR = Path(\"raw_data\")        # raw inputs live here\n",
        "DATASET_DIR = Path(\"dataset\")     # website reads from here\n",
        "CLEAN_DIR = DATASET_DIR / \"cleaned\"\n",
        "DERIVED_DIR = DATASET_DIR / \"derived\"\n",
        "\n",
        "CLEAN_DIR.mkdir(parents=True, exist_ok=True)\n",
        "DERIVED_DIR.mkdir(parents=True, exist_ok=True)\n",
        "\n",
        "def to_number(s: pd.Series) -> pd.Series:\n",
        "    return pd.to_numeric(s.astype(str).str.replace(\",\", \"\").str.strip(), errors=\"coerce\")\n",
        "\n",
        "def parse_year(val) -> float:\n",
        "    if pd.isna(val):\n",
        "        return np.nan\n",
        "    s = str(val).strip()\n",
        "    if len(s) >= 4 and s[:4].isdigit():\n",
        "        return float(s[:4])\n",
        "    for sep in (\"/\", \"-\"):\n",
        "        parts = s.split(sep)\n",
        "        if len(parts) == 3 and parts[-1].isdigit():\n",
        "            return float(parts[-1])\n",
        "    return np.nan\n",
        "\n",
        "def show_filter_report(df_before: pd.DataFrame, mask: pd.Series, title: str, sample_n: int = 10):\n",
        "    kept = df_before[mask].copy()\n",
        "    dropped = df_before[~mask].copy()\n",
        "    print(f\"=== {title} ===\")\n",
        "    print(\"rows_before:\", len(df_before))\n",
        "    print(\"rows_kept:\", len(kept))\n",
        "    print(\"rows_dropped:\", len(dropped))\n",
        "    if len(dropped):\n",
        "        print(\"\\nSample dropped rows:\")\n",
        "        display(dropped.head(sample_n))\n",
        "    return kept, dropped\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "execution_count": null,
      "outputs": [],
      "source": [
        "raw_path = RAW_DIR / \"hdx_hapi_idps_afg.csv\"\n",
        "df = pd.read_csv(raw_path)\n",
        "df.head()\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "execution_count": null,
      "outputs": [],
      "source": [
        "required = {\"admin_level\",\"reference_period_start\",\"population\"}\n",
        "missing = sorted(required - set(df.columns))\n",
        "assert not missing, f\"Missing columns: {missing}\"\n",
        "\n",
        "df2 = df.copy()\n",
        "df2[\"admin_level_str\"] = df2[\"admin_level\"].astype(str).str.strip()\n",
        "df2[\"date\"] = pd.to_datetime(df2[\"reference_period_start\"], errors=\"coerce\")\n",
        "df2[\"population_num\"] = to_number(df2[\"population\"])\n",
        "\n",
        "mask = (df2[\"admin_level_str\"] == \"1\") & df2[\"date\"].notna() & df2[\"population_num\"].notna() & (df2[\"population_num\"] > 0)\n",
        "kept, dropped = show_filter_report(df2, mask, \"IDPs filter (admin_level=1, valid date, numeric pop, pop>0)\")\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "execution_count": null,
      "outputs": [],
      "source": [
        "latest_date = kept[\"date\"].max()\n",
        "assert pd.notna(latest_date), \"No valid dates after filtering\"\n",
        "latest_iso = latest_date.strftime(\"%Y-%m-%d\")\n",
        "\n",
        "snap = kept[kept[\"date\"] == latest_date].copy()\n",
        "snap[\"admin1_name\"] = snap.get(\"admin1_name\", \"\").astype(str).str.strip()\n",
        "\n",
        "snap_out = CLEAN_DIR / \"idps_admin1_latest_clean.csv\"\n",
        "snap.to_csv(snap_out, index=False)\n",
        "snap_out, latest_iso\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "execution_count": null,
      "outputs": [],
      "source": [
        "by_prov = (snap.groupby(\"admin1_name\", as_index=False)[\"population_num\"]\n",
        "             .sum()\n",
        "             .sort_values(\"population_num\", ascending=False))\n",
        "by_prov.rename(columns={\"population_num\":\"idps_count\"}, inplace=True)\n",
        "\n",
        "out_csv = DERIVED_DIR / \"idps_latest_by_province.csv\"\n",
        "by_prov.to_csv(out_csv, index=False)\n",
        "\n",
        "total = float(by_prov[\"idps_count\"].sum())\n",
        "out_json = DERIVED_DIR / \"idps_latest_total.json\"\n",
        "out_json.write_text(json.dumps({\"latest_date\": latest_iso, \"idps_total_admin1\": total}, indent=2), encoding=\"utf-8\")\n",
        "\n",
        "(out_csv, out_json)\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "execution_count": null,
      "outputs": [],
      "source": [
        "dropped_out = CLEAN_DIR / \"idps_dropped.csv\"\n",
        "dropped.to_csv(dropped_out, index=False)\n",
        "dropped_out\n"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "name": "python",
      "version": "3.x"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}